{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = 'center'> Startup Weekend - Artificial Intelligence Bootcamp </h1>\n",
    "<h2 align='center'>A Taste of Data Science & Machine Learning </h2>\n",
    "\n",
    "<img height=400px width=400px align = 'center' src = \"http://communities.techstars.com/images/logos/swe_lockup_logo.png\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the hands on session! Let's start by importing some libraries that we will make use of throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # Linear algebra\n",
    "import seaborn as sns # Styling our plots\n",
    "import matplotlib.pyplot as plt # Plotting interface\n",
    "# Plotting in notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Functions with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this section, we will get to implement the gradient descent algorithm in order to minimize a function. \n",
    "\n",
    "As an exercise, we want find the minimimum of the 1d function  $ f(\\theta) = \\theta^2 $. We start from point $\\theta_0 = 4.0$ with $f(\\theta_0) = 4^2 = 16$. Let's draw a graph of $f(\\theta)$ to illustrate the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_values = np.arange(-5.0, 5.0,0.01)\n",
    "\n",
    "# define the function\n",
    "def f(theta):\n",
    "    return theta**2\n",
    "\n",
    "f_thetas = f(theta_values)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "for direc in ['right','top']:\n",
    "    ax.spines[direc].set_visible(False)\n",
    "\n",
    "ax.plot(theta_values, f_thetas, lw=2, color='blue')\n",
    "ax.scatter([4], f(np.array([4])), color='red', s=300)\n",
    "ax.grid(ls='--')\n",
    "ax.set_xlabel(r'$\\theta$', fontsize=25)\n",
    "ax.set_ylabel(r'f($\\theta$)', fontsize=25)\n",
    "ax.annotate(s='Minimum', xy=(0,0.5), xytext=(-1.5,5), \n",
    "            fontsize=20,  arrowprops = dict(facecolor='black', width=2))\n",
    "ax.annotate(s=r'$\\theta_0$', xy=(4,15), xytext=(4,10),\n",
    "            fontsize=20, arrowprops = dict(facecolor='black', width=2) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of $f(\\theta)$ is given by:\n",
    "\n",
    "$$ f'(\\theta)= \\dfrac{df}{d\\theta} = 2\\theta $$\n",
    "\n",
    "Remember that gradient descent updates the value of theta for a certain number of epochs according to: <br> $$ \\theta = \\theta - \\alpha \\dfrac{df}{d\\theta} $$\n",
    "\n",
    "Complete the following code snippets in order to implement the gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_descent(theta, df, alpha):\n",
    "    # TO DO: implement the gradient descent step\n",
    "    # return the updated theta value\n",
    "     pass\n",
    "\n",
    "def find_theta_min(theta0 , df, alpha, epochs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    theta0: Initial theta value    \n",
    "    df: derivative of the function to minimize\n",
    "    alpha: learning rate\n",
    "    epochs: number of epochs\n",
    "    \"\"\"\n",
    "    #TO DO: implement a for loop to repeat gradient descent for a number epochs times\n",
    "    # return the final obtained theta value \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df(theta):\n",
    "    # TO DO Define the function df (f derivative)\n",
    "    pass\n",
    "\n",
    "theta0 = np.array([4])\n",
    "theta_min  = find_theta_min(theta0, df, alpha = 0.1, epochs=50)\n",
    "print(\"Theta min is: \",theta_min)\n",
    "print(\"The minimum of f is: \",f(theta_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Now it's time to learn how to perform linear regression. We will analyze the Boston housing dataset loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston # load the boston housing dataset\n",
    "import pandas as pd\n",
    "\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['MEDV'] = boston.target\n",
    "\n",
    "# print a description of the dataset\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and plot the median house price (MEDV) as a function of the average number of rooms in a house (RM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='RM', y='MEDV', data=df, fit_reg=False, scatter_kws=dict(alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there is a linear relation between MEDV and RM. Let's implement a linear regression model to capture this relation.To do so, we will split the dataset into train and test sets. The model is first fitted on the training set and then evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Import the function train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the feature(s) X and the target y\n",
    "X  = df['RM'].values.reshape(-1,1)\n",
    "y  = df['MEDV']\n",
    "\n",
    "# TO DO: Split the dataset into a train and a test set using the function\n",
    "# train_test_split.Use 80 % of the data to train and 20% to test\n",
    "# Check the documentation of this function to do so\n",
    "# Set the parameter random_state = 123 in this function to obtain reproducible\n",
    "# results\n",
    "X_train, X_test,y_train, y_test = None\n",
    "\n",
    "# TO DO: Instantiate a LinearRegression model and name it lr then fit it to the \n",
    "# training set\n",
    "# Use the .fit() method to fit the model and the .predict() method to predict the labels\n",
    "# of the training set then assign your predictions to the array y_train_pred\n",
    "\n",
    "# TO DO: instantiate the model\n",
    "lr = None\n",
    "# TO DO: Fit the model\n",
    "\n",
    "# TO DO predict the labels of the training set\n",
    "y_pred = None\n",
    "\n",
    "# TO DO: Evaluate the model  on the training set with the .score() method\n",
    "train_score = None\n",
    "print(\"Training score: \", train_score)\n",
    "\n",
    "sns.lmplot(x='RM', y='MEDV', data=df, fit_reg=False, scatter_kws=dict(alpha=0.5))\n",
    "plt.plot(X_train, y_pred, color='red', lw=3)\n",
    "#plt.legend(loc='upper right', bbox_to_anchor = (1.1,1.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set using the method .score() of the lr instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO: Find the model's test set score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the model performs worse on unseen data points. This illustrates the problem of overfitting. We'll learn more about it in a following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In case you are interested in the implementation of a simple version linear regression using  gradient descent from scratch, kindly refer to the  <a href='https://github.com/eliekawerk/Lebanon_AI_meetup/tree/master/Linear_Regression_27_Apr_17'>link of the slides and  notebooks </a> of the AI meetup held on the 17$^{th}$ of April 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "In this section we will learn how to fit a logistic regression model to solve a classification problem. Consider the toy dataset defined in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=200, centers=2, cluster_std=0.8, random_state=125)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X[y==0,0], X[y==1,1], c='red', marker='s', label='0')\n",
    "plt.scatter(X[y==1,0], X[y==1,1], c='blue', marker='x', label='1')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to find a model that well separates the two classes 0 (negative) and 1 (positive). Let's define a plotting helper function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TO DO: Split the data intro train and test sets just as we did in the last step\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=123)\n",
    "\n",
    "# TO DO: Instatiate a Logistic Regression model and call it log_reg; \n",
    "# set the parameter C = 1000.0 \n",
    "# The C parameter will be discussed in a following section\n",
    "log_reg = None\n",
    "\n",
    "# TO DO: Fit the model to X_train and y_train using the .fit() method\n",
    "\n",
    "\n",
    "# Evaluate the model on both the training and test sets \n",
    "# using the .score() method of log_reg, then print the results\n",
    "train_score = None\n",
    "print(\"Training score: \",train_score)\n",
    "test_score = None\n",
    "print(\"Test score: \", test_score)\n",
    "\n",
    "# TO DO: call the plot_decision_regions() function with the corresponding parameters\n",
    "# in order to visualize the obtained decision regions on the whole dataset.\n",
    "plot_decision_regions(X,y, log_reg)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting and Regularization\n",
    "\n",
    "Overfitting describes the fact that a model performs well on the training set but fails to generalize on unseen data points. Let's illustrate overfitting with the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.random.seed(123)\n",
    "X = np.arange(0,5, 0.1)\n",
    "X_test = np.arange(1.15, 3.20, 0.1)\n",
    "\n",
    "np.random.seed(123)\n",
    "def f(X):\n",
    "     return 3*X  + 4 + np.random.randn(len(X)) \n",
    "\n",
    "y = f(X)    \n",
    "y_test = f(X_test)\n",
    "\n",
    "degree = 12\n",
    "poly = PolynomialFeatures(degree)\n",
    "X_poly = poly.fit_transform(X.reshape(-1,1))\n",
    "lr_poly = LinearRegression().fit(X_poly,y)\n",
    "y_pred_poly = lr_poly.predict(X_poly)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X.reshape(-1,1), y)\n",
    "y_pred = lr.predict(X.reshape(-1,1))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X,y, color='blue', alpha=0.4, label='data points')\n",
    "plt.plot(X, y_pred_poly, lw = 2, color='red' ,\\\n",
    "         label=str(degree)+r'$^{th}$ order, R$^2$ = %.2f' %lr_poly.score(X_poly, y))\n",
    "plt.plot(X, y_pred, lw = 2,  color='green',\\\n",
    "         label='1st otder, R$^2$ = %.2f' %lr.score(X.reshape(-1,1), y))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Out of sample performance\")\n",
    "print(\"-\"*12)\n",
    "print(r\"First order R2:\",lr.score(X_test.reshape(-1,1), y_test))\n",
    "print(str(degree) + r\"th order R2:\",\\\n",
    "      lr_poly.score(poly.transform(X_test.reshape(-1,1)),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first order model performs better than the 12$^{th}$ order model. Let's define an L2 penalized model (called Ridge) whose cost function is defined as follows:\n",
    "\n",
    "$$ J_{Ridge}(\\theta) = \\dfrac{1}{2m}\\sum_{i=1}^{m}{(h_{\\theta}(x^{(i)}) - y^{(i)})^2} +\n",
    " \\dfrac{\\lambda}{2m}\\sum_{j=1}^{D}{\\theta_j^2}$$\n",
    " \n",
    "Fitting a penalized 12$^{th}$ order model will penalize the complexity of the model which leads to a better performance on unseen data points. Complete the code sinppet below to fit a penalized 12$^{th}$ order polynomial with $\\lambda = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# TO DO: Instantiate a Rigde model called ridge with the parameter lambda = 1.0\n",
    "# Note that in sklearn lambda is refered to by alpha\n",
    "# Also set random_state = 123\n",
    "ridge =  None\n",
    "\n",
    "# Fit the model to X_poly and y then print the score in sample and out of sample\n",
    "# For your convenience the score printing functions are provided\n",
    "\n",
    "print(\"training performance: \", ridge.score(X_poly, y))\n",
    "X_poly_test = poly.transform(X_test.reshape(-1,1))\n",
    "print(\"testing performance: \",ridge.score(X_poly_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the $R^2$ score of the 12$^{th}$ order model went up from 0.73 to 0.77 by just adding a penalty term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "Let's go back to the classification problem we defined earlier and fit a decision tree model to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = make_blobs(n_samples=200, centers=2, random_state=125)\n",
    "\n",
    "# TO DO: Split the data into 80 % train and 20% test using train_test_split\n",
    "# Set random_state=123  to obtain reproducible results\n",
    "X_train, X_test, y_train, y_test= None\n",
    "\n",
    "# TO DO: Instantiate a decision tree classifier and fit it to X_train and y_train\n",
    "tree = None\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "# TO DO: Evaluate the model performance (accuracy) on the train and test sets\n",
    "train_score = None\n",
    "print(train_score)\n",
    "test_score = None\n",
    "print(test_score)\n",
    "\n",
    "# Plot the decision regions\n",
    "plot_decision_regions(X,y, tree)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the tree overfits the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods\n",
    "\n",
    "As presentated in the slides, ensemble methods aggregate the predictions of a group of trees in a robust way. Let's fit a Bagging classifier and a Random Forest Classifier to the classification dataset we defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (BaggingClassifier, RandomForestClassifier)\n",
    "\n",
    "X, y = make_blobs(n_samples=200, centers=2, cluster_std=0.8, random_state=125)\n",
    "X_train, X_test, y_train, y_test= \\\n",
    "train_test_split(X,y, test_size=0.2, random_state=123)\n",
    "\n",
    "# TO DO: Instantiate a Bagging classifier (name it Bag_clf) and a Random\n",
    "# Forest classifier(name it RF); both take the argument n_estimators = 100\n",
    "\n",
    "RF = None\n",
    "Bag_clf = None\n",
    "\n",
    "# Fit the estimators to X_train and y_train and plot the decison region for\n",
    "# each classifier\n",
    "\n",
    "\n",
    "# TO DO: Evaluate both models on the train and test sets\n",
    "RF_train_score = None\n",
    "RF_test_score = None\n",
    "print(\"RF train score: \", RF_train_score)\n",
    "print(\"RF test score: \", RF_test_score)\n",
    "\n",
    "Bag_clf_train_score = None\n",
    "Bag_clf_test_score = None\n",
    "print(\"RF train score: \", Bag_clf_train_score)\n",
    "print(\"RF test score: \", Bag_clf_test_score)\n",
    "\n",
    "# Plot the decision regions\n",
    "plot_decision_regions(X,y, RF)\n",
    "plt.suptitle('Random Forest')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plot_decision_regions(X,y, Bag_clf)\n",
    "plt.suptitle('Bagging Classifier')\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "K-fold cross-validation is the gold standard used to evaluate the skill of a model on small- to medium-sized datasets. Let's go ahead and evaluate each of the models we defined earlier on the make_blobs dataset. The winning model is the one with the highest mean cross-validation f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (StratifiedKFold, cross_val_score)\n",
    "\n",
    "rnd = 123\n",
    "models = {'LR': LogisticRegression(random_state= rnd),\n",
    "       'DT': DecisionTreeClassifier(random_state=rnd),\n",
    "       'BC': BaggingClassifier(random_state=rnd),\n",
    "       'RF': RandomForestClassifier(random_state=rnd)}\n",
    "\n",
    "# TO DO: Iterate over the items of models\n",
    "# refer to the key as 'name' and to the value as 'model' \n",
    "for _, _ in _:\n",
    "    # Instantiate a StratifiedKFold() split and name it kfold with the parameter n_split= 10\n",
    "    kfold = None\n",
    "    # Generate a list of CV scores using cross_val_score use the parameters cv= kfold \n",
    "    #and scoring='f1    \n",
    "    model_scores = None\n",
    "    # Print the name of the model and the mean CV f1 score\n",
    "    print(\"Mean f1 CV Score of %s is %.2f\" %(_, model_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After chossing the best scoring CV model we fit it on the entire training set and then evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_name = None\n",
    "LR_model = models[best_model_name].fit(X_train,y_train)\n",
    "print(\"Train score: \", LR_model.score(X_train,y_train))\n",
    "print(\"Test score: \", LR_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "When we fit a model on a dataset as we did in the cells above, we do not necessarily obtain the model's best skills. This is because we are not using the optimal hyperparameters of the model. The ones set by default by the authors and developers of scikit-learn are not necessarily the optimal hyperparameters of the model for our specific problem. In order to inspect the hyperparameters of a model we can use the method .get_params() as follows. We will proceed with Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = rnd)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we know which hyperparameters we want to tune, we can define a python dictionary whose keys correspond to the names of the hyperparameters and whose values are lists containing the values to be searched. This dictionary is passed to the function GridSearchCV which performs a brute force search using stratified K-fold CV. We can set the number of folds with the 'cv' argument. We can also choose the scoring metric that suits our problem with the \"scoring\" argument.\n",
    "\n",
    "After we fit the GridSearchCV object, we can retreive the optimal model using the attribute \".best_estimator_\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle # Pickle the best model\n",
    "\n",
    "RF_grid = {\n",
    "    'max_depth': [1,2,3,4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators' : [100, 200, 300]\n",
    "}\n",
    "\n",
    "RFgrid = GridSearchCV(estimator= RF , param_grid= RF_grid ,\n",
    "             scoring = 'f1', cv= 10, n_jobs=-1)\n",
    "\n",
    "RFgrid.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best params\", RFgrid.best_params_)\n",
    "print(\"Best score\", RFgrid.best_score_)\n",
    "\n",
    "best_estimator = RFgrid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_estimator.fit(X_train,y_train)\n",
    "print(\"Train score: \", best_estimator.score(X_train,y_train))\n",
    "print(\"Test score: \", best_estimator.score(X_test,y_test))\n",
    "\n",
    "# Save the best model by pickling it\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_estimator, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on, we can reload the best model with pickle.load as shown in the snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# later on load the model\n",
    "\n",
    "with open('best_model.pkl','rb') as f:\n",
    "    best_model = pickle.load(f)    \n",
    "    \n",
    "print(best_model.get_params())    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
